{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:02.901663Z","iopub.execute_input":"2025-11-27T22:07:02.902726Z","iopub.status.idle":"2025-11-27T22:07:02.907655Z","shell.execute_reply.started":"2025-11-27T22:07:02.902694Z","shell.execute_reply":"2025-11-27T22:07:02.906824Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install faker transformers accelerate -q\n\nimport pandas as pd\nimport random\nimport torch\nfrom faker import Faker\nfrom sklearn.model_selection import train_test_split\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\n\n# Configura Faker para dados brasileiros reais\nfake = Faker('pt_BR')\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Ambiente pronto no: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:04.330874Z","iopub.execute_input":"2025-11-27T22:07:04.331208Z","iopub.status.idle":"2025-11-27T22:07:07.686185Z","shell.execute_reply.started":"2025-11-27T22:07:04.331181Z","shell.execute_reply":"2025-11-27T22:07:07.685098Z"}},"outputs":[{"name":"stdout","text":"Ambiente pronto no: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"Iniciando Geração Massiva de Dados Hierárquicos\")\ndef aplicar_politica(tipo, valor):\n    \n    if tipo in ['cpf', 'senha', 'telefone', 'cartao', 'rg']:\n        return \"[REMOVIDO]\"\n    \n    \n    if tipo == 'nome': return \"[NOME]\"\n    if tipo == 'email': return \"[EMAIL]\"\n    \n    \n    return valor \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:11.851513Z","iopub.execute_input":"2025-11-27T22:07:11.851844Z","iopub.status.idle":"2025-11-27T22:07:11.857179Z","shell.execute_reply.started":"2025-11-27T22:07:11.851811Z","shell.execute_reply":"2025-11-27T22:07:11.856305Z"}},"outputs":[{"name":"stdout","text":"Iniciando Geração Massiva de Dados Hierárquicos\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"templates_banco = [\n    \"O cliente {nome} (CPF {cpf}) realizou um saque em {cidade}.\",\n    \"Bloqueio preventivo do cartão {cartao} pertencente a {nome}.\",\n    \"A gerente {gerente} autorizou o aumento de limite para {nome}.\",\n    \"Transação suspeita: {nome} tentou usar o cartão {cartao} em {cidade}.\",\n    \"Favor atualizar o cadastro de {nome}. Novo telefone: {telefone}.\"\n]\n\ntemplates_hospital = [\n    \"Paciente {nome}, residente em {cidade}, diagnosticado com gripe.\",\n    \"O médico {medico} solicitou exames para {nome} (RG {rg}).\",\n    \"Encaminhar resultado para o email {email} urgente.\",\n    \"Paciente {nome} internado na UTI do hospital de {cidade}.\",\n    \"Ligar para o responsável de {nome} no número {telefone}.\"\n]\n\ntemplates_rh = [\n    \"O funcionário {nome} foi promovido a {cargo} na filial de {cidade}.\",\n    \"Login de rede criado para {nome}. Senha temporária: {senha}.\",\n    \"Candidato {nome} aprovado para a vaga de {cargo}.\",\n    \"Enviar holerite para o email corporativo: {email}.\",\n    \"O colaborador {nome} esqueceu o crachá na portaria.\"\n]\n\ntemplates_juridico = [\n    \"Processo movido por {nome} contra a empresa de {cidade}.\",\n    \"O réu {nome}, portador do CPF {cpf}, nega as acusações.\",\n    \"A advogada {advogada} solicitou a revisão da pena de {nome}.\",\n    \"Intimação enviada para o endereço de {nome} em {cidade}.\",\n    \"Audiência de conciliação entre {nome} e a parte contrária.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:16.008317Z","iopub.execute_input":"2025-11-27T22:07:16.008605Z","iopub.status.idle":"2025-11-27T22:07:16.013392Z","shell.execute_reply.started":"2025-11-27T22:07:16.008584Z","shell.execute_reply":"2025-11-27T22:07:16.012752Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data_pairs = []\nnum_exemplos = 20000 \n\nprint(f\"Gerando {num_exemplos} frases.\")\n\nfor _ in range(num_exemplos):\n    dados = {\n        'nome': fake.name(),\n        'cpf': fake.cpf(),\n        'rg': fake.rg(),\n        'cidade': fake.city(),\n        'telefone': fake.phone_number(),\n        'email': fake.email(),\n        'senha': fake.password(),\n        'cartao': fake.credit_card_number(),\n        'cargo': fake.job(),\n        'medico': \"Dr. \" + fake.first_name(),\n        'gerente': fake.first_name(),\n        'advogada': \"Dra. \" + fake.first_name()\n    }\n    \n    contexto = random.choice(['banco', 'hospital', 'rh', 'juridico'])\n    \n    if contexto == 'banco': template = random.choice(templates_banco)\n    elif contexto == 'hospital': template = random.choice(templates_hospital)\n    elif contexto == 'rh': template = random.choice(templates_rh)\n    else: template = random.choice(templates_juridico)\n    \n    \n    input_text = template.format(**dados)\n    \n    \n    dados_tratados = {k: aplicar_politica(k, v) for k, v in dados.items()}\n    target_text = template.format(**dados_tratados)\n    \n    data_pairs.append([f\"anonimizar: {input_text}\", target_text])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:17.148604Z","iopub.execute_input":"2025-11-27T22:07:17.149361Z","iopub.status.idle":"2025-11-27T22:07:19.923697Z","shell.execute_reply.started":"2025-11-27T22:07:17.149332Z","shell.execute_reply":"2025-11-27T22:07:19.922888Z"}},"outputs":[{"name":"stdout","text":"Gerando 20000 frases.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"df = pd.DataFrame(data_pairs, columns=['input_text', 'target_text'])\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\nprint(f\"Dataset com {len(df)} frases gerado.\")\nprint(\"\\n Amostra de dados e hierarquia\")\npd.set_option('display.max_colwidth', None)\n\nprint(df.sample(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:20.835618Z","iopub.execute_input":"2025-11-27T22:07:20.836364Z","iopub.status.idle":"2025-11-27T22:07:20.853510Z","shell.execute_reply.started":"2025-11-27T22:07:20.836337Z","shell.execute_reply":"2025-11-27T22:07:20.852845Z"}},"outputs":[{"name":"stdout","text":"Dataset com 20000 frases gerado.\n\n Amostra de dados e hierarquia\n                                                                                            input_text  \\\n3962                         anonimizar: Candidato Caroline Melo aprovado para a vaga de Endodontista.   \n3434             anonimizar: Intimação enviada para o endereço de Giovanna Ramos em Fernandes da Mata.   \n13488  anonimizar: Intimação enviada para o endereço de Isabela Casa Grande em Marques de Albuquerque.   \n9942                    anonimizar: Intimação enviada para o endereço de Luna Moraes em Santos Alegre.   \n14083                anonimizar: O médico Dr. Lucca solicitou exames para Camila Alves (RG 125834603).   \n\n                                                                  target_text  \n3962                   Candidato [NOME] aprovado para a vaga de Endodontista.  \n3434        Intimação enviada para o endereço de [NOME] em Fernandes da Mata.  \n13488  Intimação enviada para o endereço de [NOME] em Marques de Albuquerque.  \n9942            Intimação enviada para o endereço de [NOME] em Santos Alegre.  \n14083        O médico Dr. Lucca solicitou exames para [NOME] (RG [REMOVIDO]).  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", legacy=False)\n\nclass HierarquiaDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=128): \n        self.data = dataframe.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self): return len(self.data)\n    def __getitem__(self, index):\n        row = self.data.iloc[index]\n        inputs = self.tokenizer(row['input_text'], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n        targets = self.tokenizer(row['target_text'], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n        return {'input_ids': inputs['input_ids'].flatten(), 'attention_mask': inputs['attention_mask'].flatten(), 'labels': targets['input_ids'].flatten()}\n\ntrain_dataset = HierarquiaDataset(train_df, tokenizer)\nval_dataset = HierarquiaDataset(val_df, tokenizer)\nprint(\"Tokenização feita\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:28.524282Z","iopub.execute_input":"2025-11-27T22:07:28.524966Z","iopub.status.idle":"2025-11-27T22:07:29.029353Z","shell.execute_reply.started":"2025-11-27T22:07:28.524926Z","shell.execute_reply":"2025-11-27T22:07:29.028558Z"}},"outputs":[{"name":"stdout","text":"Tokenização feita\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./resultado_hierarquia\",\n    num_train_epochs=5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    learning_rate=3e-4,\n    weight_decay=0.01,\n    logging_steps=200,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    predict_with_generate=True,\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n    tokenizer=tokenizer,\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"./modelo_final_tcc\")\ntokenizer.save_pretrained(\"./modelo_final_tcc\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T22:07:31.429742Z","iopub.execute_input":"2025-11-27T22:07:31.430164Z","iopub.status.idle":"2025-11-27T22:27:02.122938Z","shell.execute_reply.started":"2025-11-27T22:07:31.430130Z","shell.execute_reply":"2025-11-27T22:27:02.122095Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_456/244735477.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1410' max='1410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1410/1410 19:27, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.150900</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000100</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000100</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"('./modelo_final_tcc/tokenizer_config.json',\n './modelo_final_tcc/special_tokens_map.json',\n './modelo_final_tcc/spiece.model',\n './modelo_final_tcc/added_tokens.json')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\nmodel_final = T5ForConditionalGeneration.from_pretrained(\"./modelo_final_tcc\").to(device)\ntokenizer_final = T5Tokenizer.from_pretrained(\"./modelo_final_tcc\", legacy=False)\n\ndef anonimizar(texto):\n    inputs = tokenizer_final(f\"anonimizar: {texto}\", return_tensors=\"pt\").input_ids.to(device)\n    outputs = model_final.generate(inputs, max_length=128, num_beams=2, early_stopping=True)\n    return tokenizer_final.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:24:07.954343Z","iopub.execute_input":"2025-11-27T23:24:07.954955Z","iopub.status.idle":"2025-11-27T23:24:07.965648Z","shell.execute_reply.started":"2025-11-27T23:24:07.954931Z","shell.execute_reply":"2025-11-27T23:24:07.964762Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2214550853.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./modelo_final_tcc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./modelo_final_tcc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'T5ForConditionalGeneration' is not defined"],"ename":"NameError","evalue":"name 'T5ForConditionalGeneration' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"testes = [\n    (\"FÁCIL\", \"O cliente João Silva tem o CPF 111.222.333-44.\"),\n    (\"FÁCIL\", \"A funcionária Maria Oliveira mora em Curitiba.\"),\n    (\"FÁCIL\", \"Login: admin. Senha: password123.\"),\n    (\"FÁCIL\", \"Favor enviar email para suporte@empresa.com.br.\"),\n\n    \n    (\"MÉDIO\", \"Meu CPF é 04925133330 (sem pontuação).\"),  \n    (\"MÉDIO\", \"Ligar para (19) 99888-7777 urgente.\"),       \n    (\"MÉDIO\", \"O Dr. Carlos atende no Hospital Sírio-Libanês.\"), \n    (\"MÉDIO\", \"Acesso liberado para roberto.santos@gmail.com.\"), \n    \n    \n    (\"DIFÍCIL\", \"O Pedro foi promovido.\"),                  \n    (\"DIFÍCIL\", \"A Rosa comprou flores.\"),                  \n    (\"DIFÍCIL\", \"Falar com o Leão.\"),                       \n    (\"DIFÍCIL\", \"Eu sou Arlyson.\"),                         \n    \n   \n    (\"HARDCORE\", \"Lebron James joga no Los Angeles Lakers.\"), \n    (\"HARDCORE\", \"O juiz Sergio Moro e o ex-presidente Lula.\"), \n    (\"HARDCORE\", \"A empresa Ford demitiu o funcionário Ford.\"), \n    (\"HARDCORE\", \"Meu nome é Null e meu CPF é zero.\"),      \n]\n\nresultados = []\n\nfor nivel, frase in testes:\n    saida = anonimizar(frase)\n    print(f\"[{nivel}]\")\n    print(f\"Entrada: {frase}\")\n    print(f\"Saída:   {saida}\")\n    \n    \n    resultados.append({'Nível': nivel, 'Entrada': frase, 'Saída': saida})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:24:03.433708Z","iopub.execute_input":"2025-11-27T23:24:03.434258Z","iopub.status.idle":"2025-11-27T23:24:03.445791Z","shell.execute_reply.started":"2025-11-27T23:24:03.434233Z","shell.execute_reply":"2025-11-27T23:24:03.444766Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2897769203.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnivel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msaida\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manonimizar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{nivel}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Entrada: {frase}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'anonimizar' is not defined"],"ename":"NameError","evalue":"name 'anonimizar' is not defined","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"import torch\n\nmodel_final = T5ForConditionalGeneration.from_pretrained(\"./modelo_final_tcc\").to(device)\ntokenizer_final = T5Tokenizer.from_pretrained(\"./modelo_final_tcc\", legacy=False)\n\ndef anonimizar_frase(texto):\n    entrada = f\"anonimizar: {texto}\"\n    inputs = tokenizer_final(entrada, return_tensors=\"pt\").input_ids.to(device)\n    \n    outputs = model_final.generate(\n        inputs, \n        max_length=128, \n        num_beams=2,       \n        early_stopping=True\n    )\n    \n    # 3. Decodifica\n    return tokenizer_final.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"Página de Anonimização\")\nprint(\"Digite uma frase e aperte ENTER para ver o resultado.\")\nprint(\"Digite 'SAIR' para encerrar.\")\nprint(\"=\"*60)\n\nwhile True:\n    try:\n        frase_usuario = input(\"\\nDigite a frase: \")\n        \n        \n        if frase_usuario.lower() in ['sair', 'exit', 'pare']:\n            print(\"\\nEncerrando sistema!\")\n            break\n        \n        if len(frase_usuario.strip()) == 0:\n            continue\n\n        \n        resultado = anonimizar_frase(frase_usuario)\n        \n        \n        print(\"-\" * 60)\n        print(f\"Apos a anonimização:\")\n        print(f\" {resultado}\")\n        \n        \n    except KeyboardInterrupt:\n        print(\"\\n Sistema interrompido.\")\n        break\n    except Exception as e:\n        print(f\"Erro: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T23:23:21.202190Z","iopub.execute_input":"2025-11-27T23:23:21.203126Z","iopub.status.idle":"2025-11-27T23:23:54.220777Z","shell.execute_reply.started":"2025-11-27T23:23:21.203091Z","shell.execute_reply":"2025-11-27T23:23:54.220202Z"}},"outputs":[{"name":"stdout","text":"Página de Anonimização\nDigite uma frase e aperte ENTER para ver o resultado.\nDigite 'SAIR' para encerrar.\n============================================================\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nDigite a frase:  ok\n"},{"name":"stdout","text":"Erro: name 'anonimizar_frase' is not defined\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nDigite a frase:  sair\n"},{"name":"stdout","text":"\nEncerrando sistema!\n","output_type":"stream"}],"execution_count":13}]}